{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Notes on Template Matching By CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Template Matching Survey\n",
    "\n",
    "### Area-Based Approach\n",
    "Compute correlation of intensities, e.g., NCC\n",
    "\n",
    "### Feature-Based Approach\n",
    "Genreate feature map first, e.g., gradient. Extract edges and only match nearby pixels instead of whole pattern. Generally, it is the gradient direction of edge pixels, rather than intensity of edge pixels are matched.\n",
    "\n",
    "To achieve rotation and scale invariance, multi-angle and multi-scale matching are performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Try MatchNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use feature tower of MatchNet and fix the weights trained by zixin, but train our own bottleneck and metric. The bottleneck first convert the dimension of feature map to 512x1x1 by **fully convolution layer** which functions the same as fc layer. Then the metric also leverages the **fully convolution layer** with **kernel size equal to 1** and produces the final softmax estimation of match confidence 2x1x1.\n",
    "\n",
    "We train and test on the data where positive patch pairs are the same and negative pairs are the same. The accuracy reaches 99.9% because both the positive and negative samples are very simple.\n",
    "\n",
    "Multi-view patch pairs with rotations are also trained and tested. The accuracy is also good but not discriminative any more. Rotation invariance can be achieved.\n",
    "\n",
    "### Add small translation offsets\n",
    "To incorporate some variance for better localization, I add small offsets of translation varying from 0 to 4. In training, first fix the feature tower and only train the bottleneck layer and the metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## MatchNet+Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then we try to add sibling regression network to estimate the transformation parameters between patch pairs while maintaining the discrination of metric.\n",
    "\n",
    "The training strategy generally follows:\n",
    "* Fix feature towers' weights and train the bottleneck layer and metric on positive and negative patch pairs. The positive patch pairs undergoes handmade transformations between them.\n",
    "* Fix bottleneck and metric. Train the regression branch.\n",
    "* Relax the bottleneck layer and the sibling metric and regression branches and train all of them with adjusted loss weights\n",
    "* Finally relax the feature towers if necessary\n",
    "\n",
    "The weights are fixed by setting below option to top layers. Repeat m times if there are m inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "propagate_down: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Aspect Ratio+Scale\n",
    "The first case of transformation is aspect ratio and scale (therefore, dof = 2). The scale ratios in x and y dimension vary from 1 to 2, thus the aspect ratio varies from 1/2 to 2. Since the scale ratio is no less than 1, the trasformed patches have smaller sizes. The regression results are quite good.\n",
    "![regression with aspect ratio and scale](images/regression_aspect_ratio_and_scale.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Aspect Ratio+Scale+Translation\n",
    "Besides the variance of aspect ratio and scale, variation of translation offsets are added (therefore, dof = 4). The offsets in x and y dimension vary from zero to the width or height of transformed smaller patch.\n",
    "\n",
    "Report on traning:\n",
    "* Fix feature towers, bottleneck layer and regression branch, just train the metric branch. The softmax loss reaches 0.12\n",
    "* Fix feature towers and regression branch, train the bottleneck layer and metric branch. The softmax loss reaches 0.06 and the accuracy reaches 97%.\n",
    "<span style=\"color:red\">(Although the accuracy of pairwise patches is high, the locating accruacy is very low. The confidences of positve subpatches are very low. I have not figure out the reason.)</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
